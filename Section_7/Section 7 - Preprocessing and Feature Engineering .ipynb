{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for machine learning algorithms to work properly they require their input data to be formatted in certain ways. The preprocessing phase handles these formatting requirements through a number of different techniques such as binarization, mean removal, scaling, normalization, and label encoding. Similarly, feature engineering is about taking any present information and turning it into a numerically illustrative feature matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Numerical values are transformed into Boolean values represented by zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26516553  0.04466798]\n",
      " [ 0.03344112  0.07077217]\n",
      " [ 0.79311455  0.56114724]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "inputData = np.random.rand(3, 2)\n",
    "print(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized Data:\n",
      " [[0 0]\n",
      " [0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Binarize data with values over .5 being 1 and those below 0\n",
    "binData = np.where(inputData > .5, 1, 0)\n",
    "print(\"Binarized Data:\\n\", binData)\n",
    "\n",
    "# Alternative\n",
    "# inputData = inputData.reshape(-1, 1)\n",
    "# data_binarized = preprocessing.Binarizer(threshold=.5).transform(inputData) \n",
    "# print(\"\\nBinarized Data:\\n\", data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Mean Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Removing the mean involves setting it to zero and having a standard deviation of ones. This helps reduce bias in the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      " [[ 0.26516553  0.04466798]\n",
      " [ 0.03344112  0.07077217]\n",
      " [ 0.79311455  0.56114724]]\n",
      "\n",
      "Mean: [ 0.36390707  0.22552913]\n",
      "Standard Deviation: [ 0.31789762  0.237557  ]\n"
     ]
    }
   ],
   "source": [
    "# Mean and standard deviation before mean removal\n",
    "print(\"Input Data:\\n\", inputData)\n",
    "print(\"\\nMean:\", inputData.mean(axis=0))\n",
    "print(\"Standard Deviation:\", inputData.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      " [[-0.31060797 -0.7613379 ]\n",
      " [-1.03953576 -0.6514519 ]\n",
      " [ 1.35014373  1.4127898 ]]\n",
      "\n",
      "Mean: [  7.40148683e-17   7.40148683e-17]\n",
      "Standard Deviation: [ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Mean and standard deviation after mean removal\n",
    "scaledData = preprocessing.scale(inputData)\n",
    "print(\"Input Data:\\n\", scaledData)\n",
    "print(\"\\nMean:\", scaledData.mean(axis=0))\n",
    "print(\"Standard Deviation:\", scaledData.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As the name implies this technique helps to scale down the variance of the input data so as to avoid any artificially large or small inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      " [[ 0.26516553  0.04466798]\n",
      " [ 0.03344112  0.07077217]\n",
      " [ 0.79311455  0.56114724]]\n",
      "\n",
      "Min max scaled data:\n",
      " [[ 0.30503161  0.        ]\n",
      " [ 0.          0.05054257]\n",
      " [ 1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Min max scaling with a feature range from 0 and 1\n",
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(inputData)\n",
    "print(\"Input Data:\\n\", inputData)\n",
    "print(\"\\nMin max scaled data:\\n\", data_scaled_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This process regulates the values in the input data to common scale. L1 normalization, or Least Absolute Deviations, makes it so that the sum of absolute values in each row is equal to one. L2 normalization, or least squares, has a similar approach by evaluating that the sum of the squared row values is equal to one. L1 normalization tends to be more resistant to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Normalized Data:\n",
      " [[ 0.85583231  0.14416769]\n",
      " [ 0.32089113  0.67910887]\n",
      " [ 0.58564345  0.41435655]]\n",
      "\n",
      "L2 Normalized Data:\n",
      " [[ 0.98610675  0.16611283]\n",
      " [ 0.42722492  0.90414538]\n",
      " [ 0.81633616  0.57757707]]\n"
     ]
    }
   ],
   "source": [
    "L1NormalizedData = preprocessing.normalize(inputData, norm='l1')\n",
    "L2NormalizedData = preprocessing.normalize(inputData, norm='l2')\n",
    "print(\"L1 Normalized Data:\\n\", L1NormalizedData)\n",
    "print(\"\\nL2 Normalized Data:\\n\", L2NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Labels are often times an attribute of data sets, and sometimes these labels are in a non-numeric format. To prepare the data to be used in machine learning functions it is necessary to covert word labels into numbers though the use of a label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Mapping:\n",
      "AAPL --> 0\n",
      "AMD --> 1\n",
      "MSFT --> 2\n",
      "NVDA --> 3\n"
     ]
    }
   ],
   "source": [
    "# Sample input labels \n",
    "inputLabels = ['NVDA', 'AAPL', 'AMD', 'MSFT'] \n",
    "\n",
    "# Create a label encoder and fit the labels \n",
    "encoder = preprocessing.LabelEncoder() \n",
    "encoder.fit(inputLabels) \n",
    "\n",
    "# Print the mapping  \n",
    "print(\"\\nLabel Mapping:\") \n",
    "for i, item in enumerate(encoder.classes_): \n",
    "    print(item, '-->', i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Labels = ['AMD', 'NVDA', 'AAPL', 'MSFT']\n",
      "Encoded Values = [1, 3, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Encode a set of labels using the encoder \n",
    "testLabels = ['AMD', 'NVDA', 'AAPL', 'MSFT'] \n",
    "encodedValues = encoder.transform(testLabels) \n",
    "print(\"\\nTest Labels =\", testLabels) \n",
    "print(\"Encoded Values =\", list(encodedValues)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imputation of Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When there is missing data in an array a common approach is to replace the missing value with something appropriate. This approach is referred to as imputation of missing values, and there are a variety of techniques that can be used to accomplish this. Basic imputation involves replacing the missing value with a mean, median, or most frequent value strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.5   1.    5.  ]\n",
      " [ 9.    7.    3.  ]\n",
      " [ 1.    5.    3.75]\n",
      " [ 4.    5.    6.  ]\n",
      " [ 8.    4.5   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "incompleteData = np.array([[ nan, 1, 5 ],\n",
    "                           [ 9, 7, 3 ],\n",
    "                           [ 1, 5, nan ],\n",
    "                           [ 4, 5, 6 ],\n",
    "                           [ 8, nan, 1 ]])\n",
    "\n",
    "imp = Imputer(strategy='mean')\n",
    "fixedData = imp.fit_transform(incompleteData)\n",
    "print(fixedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Transforming Inputs Through Derived Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sometimes the input data just isn’t enough to be described well by certain modelling methods. A way to get around this is by deriving and adding additional features to the data in order to improve model flexibility. Model improvement can therefore be done by transforming the inputs instead of changing the model itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIdwAkMz/ArgH5eGrWpDYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2120f522898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x = np.array([1, 3, 5, 7, 9])\n",
    "y = np.array([5, 3, 2, 4, 7])\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGgFJREFUeJzt3WtwXPd53/HvgxtxIUEQu+AFgEAA\nCwmypNAEBYrEwpZUSQ7tRJUZN2nt2h3FbYZKnHjkuGUm7JuOO9MXHXY6yatMOHZTZ+I44ygUZ+pJ\nTWumTV2TICVQpEhZEmICvAK84EKABAEQwO7TF2exIlmKXEhY7B7g95nBADhY4DyDWfxw9n+ecx5z\nd0REJDwKcl2AiIjMj4JbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuIhExR\nNn5oNBr1xsbGbPxoEZEl6dixY0PuXpPJY7MS3I2NjXR3d2fjR4uILElmdi7Tx2qpREQkZBTcIiIh\no+AWEQkZBbeISMgouEVEQuaBwW1mrWZ24ra362b2rcUoTkRE/n8PbAd09x5gM4CZFQL9wOtZrktE\nJDQOHO9n78EeBkYnqa0qY/eOVna21WVtf/Pt434e6HX3jPsNRUSWsgPH+9mz/xSTMwkA+kcn2bP/\nFEDWwnu+a9xfBn6YjUJERMJo78GedGjPmZxJsPdgT9b2mXFwm1kJ8BLwtx/x9V1m1m1m3YODgwtV\nn4hIXhsYnZzX9oUwnyPuLwBvu/uVe33R3fe5e7u7t9fUZHS5vYhI6NVWlc1r+0KYT3B/BS2TiIjc\nYfeOVsqKC+/YVlZcyO4drVnbZ0YnJ82sHPgc8ErWKhERCaG5E5B511Xi7hNAJGtViIiE2M62uqwG\n9d105aSISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJG\nwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuI\nhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQyCm4zqzKz\n18zsAzN738w6sl2YiIjcW1GGj/tT4Cfu/ptmVgKUZ7EmERG5jwcGt5lVAk8Dvw3g7tPAdHbLEhGR\nj5LJUkkzMAj8hZkdN7PvmllFlusSEZGPkElwFwFbgD9z9zbgJvDHdz/IzHaZWbeZdQ8ODi5wmSIi\nMieT4L4IXHT3o6nPXyMI8ju4+z53b3f39pqamoWsUUREbvPA4Hb3y8AFM2tNbXoeeC+rVYmIyEfK\ntKvkm8APUh0lfcDXs1eSiIjcT0bB7e4ngPYs1yIiIhnQlZMiIiGj4BYRCRkFt4hIyCi4RURCRsEt\nIhIyCm4RkZBRcIuIhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISM\ngltEJGQU3CIiIaPgFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYR\n+YTcnXPDN7kwMrEo+ytalL2IiCwxl8em6Oob4tDpYbp6h+kfneTljo1854tPZH3fCm4RkQxcuznN\nkb5hDvcOc6h3iL7BmwBUlRfT0Rzhd59p5rMP1yxKLQpuEZF7GL81y1tnRjjcO8Th3mHeu3Qdd6go\nKeSppmq+srWBjliExzZUUlBgi1qbgltEBJiaSfD2+Wt09QZH1e9cGGU26ZQUFrBlYxXffuER4i0R\nNtVXUVyY29ODCm4RWZZmE0lO9o+lgnqI7rPXuDWbpMBgU30VrzzTTDwW5cmNaygtLsx1uXfIKLjN\n7CxwA0gAs+7evtCFHDjez96DPQyMTlJbVcbuHa3sbKtb6N2IyDKVTDo9V25w6PQQXb3DHD0zwvit\nWQAeXb+Kr27bSGdLhK1N1VSWFue42vubzxH3P3H3oWwUceB4P3v2n2JyJgFA/+gke/afAlB4i8jH\n4u6cHZ5IB3VX3zAjN6cBaIpW8NLmWjpjUbY3VxNZuSLH1c5PXiyV7D3Ykw7tOZMzCfYe7FFwi0jG\nLo1Ncvh00PXR1TvMpbEpANZXlvJsaw2dsSgdsQi1VWU5rvSTyTS4HfipmTnw5+6+7+4HmNkuYBdA\nQ0PDvIoYGJ2c13YREYDh8Vsc6RtJB/WZoaBFr7qihI7mCPGWCPFYlMZIOWaL2/mRTZkGd6e7D5jZ\nWuANM/vA3X92+wNSYb4PoL293edTRG1VGf33COmw/1cUkYV1Y2qGN8+MBL3Up4f44PINAFauKGJb\nUzVf3dZAZ0uU1nWrFr1FbzFlFNzuPpB6f9XMXgeeAn52/+/K3O4drXescQOUFReye0frQu1CREJo\naibBsXPX0r3UJy+OkUg6K4oKaG9cw+4drXTEImyqW01Rjlv0FtMDg9vMKoACd7+R+vhXgf+4kEXM\nrWOrq0RkeZtJJDl5cZTDp4Ne6mPnrzE9m6SwwNj8UBXfeDZGRyzClob8a9FbTJkcca8DXk+tDxUB\nf+3uP1noQna21SmoRZaZZNJ579L1dC/1m2dGuDmdwAwe21DJyx0biceibG2qZuWKvOilyAsP/E24\nex/w6UWoRUSWOHenb+gmh08HSx9dfcOMTswAEKup4Etb6onHImxvjrCmoiTH1eYv/QsTkazqH51M\n91If7h3iyvVbANRVlfG5T60j3hKhoznK+tWlOa40PBTcIrKghsZvpUP6cO8w54aDe1RHV5bQEYsS\nj0WIxyI0VC+tFr3FpOAWkU9kbDJo0Zs7qu65ErTorSotYntzhN+ONxKPRXlk3UoF9QJRcIvIvExO\nJ+g+F/RSHz49xKn+MZIOpcUFbG2sZmdbHfFYhMdrK5dVi95iUnCLyH1NzyZ5J92iN8Tx86NMJ5IU\nFRhtDVV887mHiccibG6oYkXR8m3RW0wKbhG5QyLpvDdwPb1G/dbZESZSLXpP1K7m658Jlj62Nq6h\nvEQRkgv6rYssc+7O6avjwdJH7xBH+kYYmwxa9FrWruS3nqwn3hJle1OE1eX5fbvT5ULBLbIMXRiZ\nSB9RH+4dZvBG0KL3UHUZn398fdCiF4uwdpVa9PKRgltkGbh6Yypo0Ts9zOG+IS6MBDd1q1m1It2e\nF49Feai6PMeVSiYU3CJL0NjEDF19w3Sljqp/eXUcgMrSIjpiEX7nM810tkSI1ahFL4wU3CJLwMT0\nLG+eGUkPun13YAz34C6bTzVV85tP1hOPRXmstpLCJXy70+VCwS0SQrdmE5w4P8qh3uCo+sSFUWYS\nwUTytoYqvvV8MJH80/VVlBSpl3qpUXCLhEAi6bzbP5bu/Hjr7AhTM8FE8l+pW83vfLaZeCxC+8Zq\nykrUS73UKbhF8pC7849XxjncO8Sh08McPTPMjalgInnrulV8eWsw6eWppmpWl6lFb7lRcIvkAXfn\n/MhEeiTXkb5hhsaDieQbI+W8uGkD8ViU7c0RalaFayK5LDwFt0iOXB6boqsvOKLu6h1Oz11du2oF\nn324ho5Um179GrXoyZ0U3CKL5NrNaY70BV0fh3qH6BsMJpJXlRfT0Rzhd59pJt4SpTlaoRY9uS8F\nt0iWjN+a5a0zI+krFN+7dB13qCgJWvS+srWBjliExzZULumJ5LLwFNwiC2RqJsHb56+le6nfuTDK\nbDJo0Xty4xq+/ULQorepvopi3e5UPgEFt8jHNJtIcrJ/LD3tpfvsNW6lJpJvql/NK880E49FeXLj\n8p5ILgtPwS2SoWTS+eDyDQ73BpNejp4ZYfxW0KL36PpVfG37RuKxCFubqqksVYueZI+CW+QjuDtn\nhyfSI7m6+oYZuRm06DVFK3hpcy2dsSjbm6uJrFSLniweBbfIbS6NTXIoNemlq3eYS2NTAKyvLOXZ\n1hriqWG3tVVlOa5UljMFtyxrw+O36Eq16HX1DnNmKGjRq64ooaM5uCd1Z0uUxogmkkv+UHDLsnJj\nam4ieXBU/cHlYCL5yhVFbGuq5qvbGojHojy6fpVa9CRvKbhlSZuaSXDs3LX0PT9O9Y+RSDorigpo\nb1zD7h2tdMQibKpbrYnkEhoKbllSZhJJTqYmkh/qHeLtc8FE8sIC49P1q/m9Z2LEWyJsaVCLnoSX\ngltCLZl03rt0na7UZeRvngkmkgM8tqGSl+Mbg4nkTdWsXKGnuywNeiZLqLg7vYM30yO5uvqGGZ0I\nJpI311TwpS11dMaibGuOUF1RkuNqRbJDwS157+K1iXTXx+HeIa5cDyaS164u5YVPraOzJUJHc5T1\nqzWRXJaHjIPbzAqBbqDf3V/MXkmy3A2N30oFdXBUfW54AoBIRUnqVqdROlsiNFSrRU+Wp/kccb8K\nvA9UZqkWWabGJmc4elsvdc+VoEVv1YoitjVHeLmjkc6WKI+s00TyxXLgeD97D/YwMDpJbVUZu3e0\nsrOtLtdlSUpGwW1m9cCvA/8J+HZWK5Ilb3I6Qfe5kdQAgSFO9Y+RdCgtLmBrYzVfbKslHovyRG2l\nWvRy4MDxfvbsP8XkTHCSt390kj37TwEovPNEpkfcfwL8EbAqi7XIEjU9m+Sd21r0jp+/xkzCKSow\n2hqq+IPnHiYei9DWUMWKIrXo5dregz3p0J4zOZNg78EeBXeeeGBwm9mLwFV3P2Zmz97ncbuAXQAN\nDQ0LVqCETyLpvDdwPbjopXeYt86MMDmTwAwer63kX3c20RGLsLWxmgq16OWdgdQItUy3y+LL5K+m\nE3jJzH4NKAUqzeyv3P1rtz/I3fcB+wDa29t9wSuVvOXunL46zuFU18eRvhHGJoMWvZa1K/nn7fV0\npO6iV1WuFr18V1tVlp5/efd2yQ8PDG533wPsAUgdcf+7u0Nblp8LIxPpkVyHe4cZvBG06NVVlbHj\n8XV0tkTpaI6wtlItemGze0frHWvcAGXFheze0ZrDquR2ep0qGbl6Yyrooz49zOG+IS6MBEdk0ZUr\niKemkXe2RHmoWhPJw25uHVtdJfnL3Bd+VaO9vd27u7sX/OfK4hmbmOHImWEOnw6Oqn95dRyAytIi\ntjd/GNQta9WiJ7IQzOyYu7dn8lgdcQsAE9OzvHX2Wjqo3x0Ywz14iby1qZp/9mQ9nbEoj9VWUqjb\nnYrklIJ7mbo1m+DE+VEOpa5QPHFhlJmEU1xotDWs4dXnHyYei7L5oSpKitRLLZJPFNzLRCLpvNs/\nlu78eOvsCFMzSQoMnqhbzb/5TDPxWIT2xjWUl+hpIZLP9Be6RLk7/3hlPN35caRvmBtTwUTyR9at\n5MtbG4jHImxrirC6XBPJRcJEwb1EuDvnRybS7XldvUMMjQcTyRuqy3lx0wY6YkGLXs0qTSQXCTMF\nd4hduT4VHFGfDsJ67qKJtatW8JmWKPFUL7Va9ESWFgV3iIxOTKfuSR2sU/cOBhPJV5cV09Ec4ZVn\nmonHosRqKtSiJ7KEKbjz2M1bs7x5diTdovfepeu4Q3lJIU81VfMvtj5EPBblsQ2VmkgusowouPPI\n1EyC4+dH0ycU37kwymzSKSksYMvGKv7whUfobImwqb6KYt3uVGTZUnDn0GwiyanbWvS6z17j1mzQ\norepvopdTwdLH+2NmkguIh9ScC+iZNLpuXIj3fVxtG+EG7eCFr1H16/iq9s2Eo9FeKq5mspSteiJ\nyL0puLPI3Tk7/OFd9I70DjN8M2jRa4pW8E831xKPRdjeHCG6Ui16IpIZBfcCuzQ2mW7P6+odYmBs\nCoD1laU801pDPBalIxahTvc2FpGPScH9CY3cnGvRG6Krd5i+oaBFb015MfFYlG+kbnnaFFWLnogs\nDAX3PN2YmuHNMyPpKxTfv3QdgIqSQrY1R/iX2xqIx6I8un6VWvREJCsU3A8wNZPg7XPXOJRapz55\ncYxE0ikpKqB94xp272ilIxbhV+pWq0VPRBaFgvsuM4kkJy+OpS96OXb+GtOzSQoLjE/Xr+Ybz8bo\niEXY0qAWPRHJjWUf3Mmk8/7l63T1DnPo9BBvnhnh5nQwa++xDZW83LGReCzK1qZqVmoiuYjkgWWX\nRO5O39DNdNdHV+8w1yaCieTNNRX8xpY6OmNRtjVHqK7QRHIRyT/LIrj7Ryc5fHoofYOmy9eDFr3a\n1aU8/6l1dLZE6GiOsn61JpKLSP5bksE9NH7rjrvonRueACBSUUJHLEI8FqWzJUJDdbla9EQkdJZE\ncF+fmuFo30i6l/qDyzcAWLWiiG3NEV7uaKSzJcoj6zSRXETCL5TBPTmdoPvch73Upy6OknQoLS5g\na2M1L22upTMW5fHaSorUoiciS0wognt6NsnJi6McOh0sfRw/P8p0IklRgdHWUMUfPPcw8ViEtoYq\nVhSpRU9Elra8DO5E0nn/0nUOpXqp3zo7wsR0AjN4onY1X+9spCMWYWtjNRVq0RORZSavUu/HJwf4\nH+8McKRvhLHJoEXv4bUr+a0n69ODbjWRXESWu7wK7u6z1/jFwHU+//h64i0ROpojrK1Ui56IyO3M\n3Rf8h7a3t3t3d/e8v296NklJkU4misjyY2bH3L09k8fmVUoqtEVEHkxJKSISMg8MbjMrNbM3zewd\nM/uFmX1nMQoTEZF7y+Tk5C3gOXcfN7Ni4Odm9j/d/UiWa5P7OHC8n70HexgYnaS2qozdO1rZ2VaX\n67JEZBE8MLg9OHs5nvq0OPW28Gc0JWMHjvezZ/8pJmeC28/2j06yZ/8pAIW3yDKQ0Rq3mRWa2Qng\nKvCGux/NbllyP3sP9qRDe87kTIK9B3tyVJGILKaMgtvdE+6+GagHnjKzJ+5+jJntMrNuM+seHBxc\n6DrlNgOjk/PaLiJLy7y6Stx9FPgH4PP3+No+d2939/aampoFKk/upbaqbF7bRWRpyaSrpMbMqlIf\nlwEvAB9kuzD5aLt3tFJ217zLsuJCdu9ozVFFIrKYMukq2QB838wKCYL+R+7+4+yWJfczdwJSXSUi\ny1MmXSUngbZFqEXmYWdbnYJaZJnSlZMiIiGj4BYRCRkFt4hIyCi4RURCRsEtIhIyCm4RkZBRcIuI\nhIyCW0QkZBTcIiIho+AWEQkZBbeISMgouEVEQkbBLSISMgpuEZGQUXCLiISMgltEJGQU3CIiIaPg\nFhEJGQW3iEjIKLhFREJGwS0iEjIKbhGRkFFwi4iEjIJbRCRkFNwiIiGj4BYRCRkFt4hIyCi4RURC\nRsEtIhIyCm4RkZBRcIuIhEzRgx5gZg8BfwmsB5LAPnf/02wXJrKQDhzvZ+/BHgZGJ6mtKmP3jlZ2\nttXluiyRj+WBwQ3MAv/W3d82s1XAMTN7w93fy3JtIgviwPF+9uw/xeRMAoD+0Un27D8FoPCWUHrg\nUom7X3L3t1Mf3wDeB/Rsl9DYe7AnHdpzJmcS7D3Yk6OKRD6Zea1xm1kj0AYcvcfXdplZt5l1Dw4O\nLkx1IgtgYHRyXttF8l3GwW1mK4G/A77l7tfv/rq773P3dndvr6mpWcgaRT6R2qqyeW0XyXcZBbeZ\nFROE9g/cfX92SxJZWLt3tFJWXHjHtrLiQnbvaM1RRSKfTCZdJQZ8D3jf3f9r9ksSWVhzJyDVVSJL\nRSZdJZ3AvwJOmdmJ1LZ/7+5/n72yRBbWzrY6BbUsGQ8Mbnf/OWCLUIuIiGRAV06KiISMgltEJGQU\n3CIiIaPgFhEJGQW3iEjImLsv/A81GwTOfcxvjwJDC1jOQlFd86O65kd1zc9SrGuju2d02XlWgvuT\nMLNud2/PdR13U13zo7rmR3XNz3KvS0slIiIho+AWEQmZfAzufbku4COorvlRXfOjuuZnWdeVd2vc\nIiJyf/l4xC0iIveRN8FtZv/NzK6a2bu5ruV2ZvaQmf1vM3vfzH5hZq/muiYAMys1szfN7J1UXd/J\ndU1zzKzQzI6b2Y9zXcvtzOysmZ0ysxNm1p3regDMrMrMXjOzD1LPsY5c1wRgZq2p39Pc23Uz+1Ye\n1PWHqef7u2b2QzMrzXVNAGb2aqqmXyzG7ylvlkrM7GlgHPhLd38i1/XMMbMNwIbbhyUDO3M9LDl1\nn/QKdx9PDbr4OfCqux/JZV0AZvZtoB2odPcXc13PHDM7C7S7e970/5rZ94H/6+7fNbMSoNzdR3Nd\n1+3MrBDoB7a5+8e9PmMh6qgjeJ4/5u6TZvYj4O/d/b/nqqZUXU8AfwM8BUwDPwF+z91/ma195s0R\nt7v/DBjJdR13y9dhyR4YT31anHrL+X9hM6sHfh34bq5ryXdmVgk8TTCoBHefzrfQTnke6M1laN+m\nCCgzsyKgHBjIcT0AnwKOuPuEu88C/wf4jWzuMG+COwzuNyw5F1JLEieAq8Ab7p4Pdf0J8EdAMteF\n3IMDPzWzY2a2K9fFAM3AIPAXqaWl75pZRa6LuocvAz/MdRHu3g/8F+A8cAkYc/ef5rYqAN4Fnjaz\niJmVA78GPJTNHSq4M/SgYcm54O4Jd98M1ANPpV6y5YyZvQhcdfdjuazjPjrdfQvwBeD3U8tzuVQE\nbAH+zN3bgJvAH+e2pDullm9eAv42D2pZA3wRaAJqgQoz+1puqwJ3fx/4z8AbBMsk7wCz2dyngjsD\n+T4sOfXy+h+Az+e4lE7gpdRa8t8Az5nZX+W2pA+5+0Dq/VXgdYI1yVy6CFy87ZXSawRBnk++ALzt\n7ldyXQjwAnDG3QfdfQbYD8RzXBMA7v49d9/i7k8TLPlmbX0bFNwPlK/Dks2sxsyqUh+XETypP8hl\nTe6+x93r3b2R4OX1/3L3nB8RAZhZRerkMqnliF8leImbM+5+GbhgZnPj5p8HcnrS+x6+Qh4sk6Sc\nB7abWXnq7/J5gnNOOWdma1PvG4AvkeXfWSbDgheFmf0QeBaImtlF4D+4+/dyWxWQv8OSNwDfT53x\nLwB+5O551X6XZ9YBrwd/7xQBf+3uP8ltSQB8E/hBakmiD/h6jutJS63Xfg54Jde1ALj7UTN7DXib\nYCniOPlzBeXfmVkEmAF+392vZXNnedMOKCIimdFSiYhIyCi4RURCRsEtIhIyCm4RkZBRcIuIhIyC\nW0QkZBTcIiIho+AWEQmZ/wdPVEkXtoHxpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2120f7c2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = x[:, np.newaxis]\n",
    "model = LinearRegression().fit(X, y)\n",
    "yfit = model.predict(X)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.    1.    1.]\n",
      " [   3.    9.   27.]\n",
      " [   5.   25.  125.]\n",
      " [   7.   49.  343.]\n",
      " [   9.   81.  729.]]\n"
     ]
    }
   ],
   "source": [
    "polynomial = PolynomialFeatures(degree=3, include_bias=False)\n",
    "additionalFeaturesData = polynomial.fit_transform(X)\n",
    "\n",
    "# The feature matrix has the first column representing the original x values, \n",
    "# the second column representing x squared, and the third column representing x cubed.\n",
    "print(additionalFeaturesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no+IWEXEZFbeIiMuouEVEXEbFLSLiMv8PFXWnvjfzRtMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2120f7c6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression().fit(additionalFeaturesData, y)\n",
    "yfit = model.predict(additionalFeaturesData)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One-Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A more useful technique to altering non-numeric, or categorical, data into a numbered format is by using one-hot encoding. This approach creates extra columns in the data that represent the presence or absence of categorical features through the labels 0 or 1. Encoding like this can increase a data set dramatically if it contained a lot of varied categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'price': 100, 'quantity ': 1, 'model': 'ZX42L'},\n",
    "        {'price': 50, 'quantity ': 3, 'model': 'Y7S3'},\n",
    "        {'price': 75, 'quantity ': 2, 'model': 'SCR77'},\n",
    "        {'price': 23, 'quantity ': 4, 'model': 'LCM28R'},\n",
    "        {'price': 70, 'quantity ': 2, 'model': 'SCR77'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   1, 100,   1],\n",
       "       [  0,   0,   1,   0,  50,   3],\n",
       "       [  0,   1,   0,   0,  75,   2],\n",
       "       [  1,   0,   0,   0,  23,   4],\n",
       "       [  0,   1,   0,   0,  70,   2]], dtype=int32)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer(sparse=False, dtype=int)\n",
    "\n",
    "# The 'model' column is expanded into four separate columns based on the existing four label types, \n",
    "# and a 1 is present on the row that is associated with one of those labels. \n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model=LCM28R',\n",
       " 'model=SCR77',\n",
       " 'model=Y7S3',\n",
       " 'model=ZX42L',\n",
       " 'price',\n",
       " 'quantity ']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature (column) names\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is also possible to encode text data into numerical values by word counts with Scikit-Learn’s CountVectorizer. The occurrences of each word in each piece of text is counted and organized in a table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = ['What is your itinerary',\n",
    "        'To meet my maker',\n",
    "        'And what do you want to say to your maker',\n",
    "        'The coward dies a thousand deaths',\n",
    "        'The valiant taste of death but once']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>but</th>\n",
       "      <th>coward</th>\n",
       "      <th>death</th>\n",
       "      <th>deaths</th>\n",
       "      <th>dies</th>\n",
       "      <th>do</th>\n",
       "      <th>is</th>\n",
       "      <th>itinerary</th>\n",
       "      <th>maker</th>\n",
       "      <th>...</th>\n",
       "      <th>say</th>\n",
       "      <th>taste</th>\n",
       "      <th>the</th>\n",
       "      <th>thousand</th>\n",
       "      <th>to</th>\n",
       "      <th>valiant</th>\n",
       "      <th>want</th>\n",
       "      <th>what</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  but  coward  death  deaths  dies  do  is  itinerary  maker  ...   say  \\\n",
       "0    0    0       0      0       0     0   0   1          1      0  ...     0   \n",
       "1    0    0       0      0       0     0   0   0          0      1  ...     0   \n",
       "2    1    0       0      0       0     0   1   0          0      1  ...     1   \n",
       "3    0    0       1      0       1     1   0   0          0      0  ...     0   \n",
       "4    0    1       0      1       0     0   0   0          0      0  ...     0   \n",
       "\n",
       "   taste  the  thousand  to  valiant  want  what  you  your  \n",
       "0      0    0         0   0        0     0     1    0     1  \n",
       "1      0    0         0   1        0     0     0    0     0  \n",
       "2      0    0         0   2        0     1     1    1     1  \n",
       "3      0    1         1   0        0     0     0    0     0  \n",
       "4      1    1         0   0        1     0     0    0     0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(data)\n",
    "\n",
    "# Convert sparse matrix to a DataFrame with labeled columns\n",
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To avoid putting too much weight on words that appear very frequently the term frequency–inverse document frequency (TF–IDF) technique can be used. It weights the word counts by a measure of how often they appear in the documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>but</th>\n",
       "      <th>coward</th>\n",
       "      <th>death</th>\n",
       "      <th>deaths</th>\n",
       "      <th>dies</th>\n",
       "      <th>do</th>\n",
       "      <th>is</th>\n",
       "      <th>itinerary</th>\n",
       "      <th>maker</th>\n",
       "      <th>...</th>\n",
       "      <th>say</th>\n",
       "      <th>taste</th>\n",
       "      <th>the</th>\n",
       "      <th>thousand</th>\n",
       "      <th>to</th>\n",
       "      <th>valiant</th>\n",
       "      <th>want</th>\n",
       "      <th>what</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.550329</td>\n",
       "      <td>0.550329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.260985</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.260985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374105</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387757</td>\n",
       "      <td>0.312840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and       but    coward     death    deaths      dies        do  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.323484  0.000000  0.000000  0.000000  0.000000  0.000000  0.323484   \n",
       "3  0.000000  0.000000  0.463693  0.000000  0.463693  0.463693  0.000000   \n",
       "4  0.000000  0.387757  0.000000  0.387757  0.000000  0.000000  0.000000   \n",
       "\n",
       "         is  itinerary     maker    ...          say     taste       the  \\\n",
       "0  0.550329   0.550329  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000   0.000000  0.444002    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000   0.000000  0.260985    ...     0.323484  0.000000  0.000000   \n",
       "3  0.000000   0.000000  0.000000    ...     0.000000  0.000000  0.374105   \n",
       "4  0.000000   0.000000  0.000000    ...     0.000000  0.387757  0.312840   \n",
       "\n",
       "   thousand        to   valiant      want      what       you      your  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.444002  0.000000  0.444002  \n",
       "1  0.000000  0.444002  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.521969  0.000000  0.323484  0.260985  0.323484  0.260985  \n",
       "3  0.463693  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.387757  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(data)\n",
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the purposes of stringing together multiple steps Scikit-Learn provides a pipeline object that can be used to streamline a processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [5 3 2 4 7]\n",
      "Predicted: [ 5.  3.  2.  4.  7.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(Imputer(strategy='mean'), # Impute missing values using the mean\n",
    "                      PolynomialFeatures(degree=2), # Transform features to quadratic                     \n",
    "                      LinearRegression()) # Fit a linear regression\n",
    "\n",
    "# Predict results by applying the model to the training data\n",
    "model.fit(incompleteData, y)\n",
    "print('Actual:', y)\n",
    "print('Predicted:', model.predict(incompleteData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
